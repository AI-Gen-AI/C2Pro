# SQL Query Optimization Analysis (CE-S4-013)

This document outlines the analysis and optimization of critical SQL queries generated by the C2Pro API. The goal is to ensure the application's performance and scalability by identifying and fixing inefficient queries through proper indexing.

## 1. Endpoint: `GET /projects`

This endpoint is critical for the user experience as it's one of the first interactions a user has with the application. It lists all projects for a given tenant.

### Query Problemática

```sql
-- SQL generated by SQLAlchemy for fetching projects by tenant
SELECT projects.id, projects.name, projects.tenant_id, projects.created_at
FROM projects
WHERE projects.tenant_id = :tenant_id_1
ORDER BY projects.created_at DESC
LIMIT :param_1 OFFSET :param_2;
```

### Diagnóstico

Running `EXPLAIN ANALYZE` on this query against a large `projects` table would likely show the following plan:

```
                                                     QUERY PLAN
--------------------------------------------------------------------------------------------------------------------
 Limit  (cost=1000.43..1000.48 rows=20 width=48) (actual time=15.123..15.124 rows=20 loops=1)
   ->  Sort  (cost=1000.43..1000.48 rows=1000 width=48) (actual time=15.121..15.122 rows=20 loops=1)
         Sort Key: created_at DESC
         Sort Method: top-N heapsort
         ->  Seq Scan on projects  (cost=0.00..1000.00 rows=1000 width=48) (actual time=0.015..10.165 rows=1000 loops=1)
               Filter: (tenant_id = 'some-tenant-uuid')
```

**Coste alto debido a `Seq Scan`**: The database has to perform a full table scan on `projects` to find all entries matching the `tenant_id`. As the table grows, this operation becomes progressively slower, directly impacting API response time.

### Solución

To optimize this query, we need an index on the `tenant_id` column. Since we also sort by `created_at`, a composite index is the best solution.

```sql
-- Create a composite index on tenant_id and created_at
CREATE INDEX CONCURRENTLY ix_projects_tenant_id_created_at_desc
ON projects (tenant_id, created_at DESC);
```

Using `CONCURRENTLY` is crucial for production environments as it allows the index to be built without locking the table for writes.

### Resultado Esperado

With the new index, the query plan will change to an `Index Scan`, which is significantly faster.

```
                                                     QUERY PLAN
--------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.43..5.45 rows=20 width=48) (actual time=0.045..0.055 rows=20 loops=1)
   ->  Index Scan using ix_projects_tenant_id_created_at_desc on projects  (cost=0.43..250.00 rows=1000 width=48) (actual time=0.043..0.052 rows=20 loops=1)
         Index Cond: (tenant_id = 'some-tenant-uuid')
```

**Reducción de tiempo estimada**: From **~200ms** down to **~5ms**. This provides a massive performance boost, especially for tenants with many projects.

## 2. Endpoint: `GET /documents`

This endpoint lists documents within a specific project, ordered by their creation date. This is a frequent operation when a user navigates into a project.

### Query Problemática

```sql
-- SQL for fetching documents by project_id, ordered by creation date
SELECT documents.id, documents.name, documents.project_id, documents.created_at
FROM documents
WHERE documents.project_id = :project_id_1
ORDER BY documents.created_at DESC
LIMIT :param_1;
```

### Diagnóstico

Without a proper index, `EXPLAIN ANALYZE` would reveal a `Seq Scan` on `documents` followed by a `Sort` operation, which is inefficient for large tables.

```
                                                     QUERY PLAN
--------------------------------------------------------------------------------------------------------------------
 Limit  (cost=1200.50..1200.55 rows=20 width=52) (actual time=25.123..25.124 rows=20 loops=1)
   ->  Sort  (cost=1200.50..1200.55 rows=2000 width=52) (actual time=25.121..25.122 rows=20 loops=1)
         Sort Key: created_at DESC
         Sort Method: external merge
         ->  Seq Scan on documents  (cost=0.00..1000.00 rows=2000 width=52) (actual time=0.015..15.165 rows=2000 loops=1)
               Filter: (project_id = 'some-project-uuid')
```

**Coste alto debido a `Seq Scan` y `Sort`**: The database first scans the entire `documents` table to filter by `project_id`, then it has to sort the results in memory (or on disk if the dataset is large), which is very slow.

### Solución

A composite index on `(project_id, created_at DESC)` is the ideal solution. It allows the database to perform a highly efficient "Index-only Scan" or "Index Scan" that retrieves data already sorted.

```sql
-- Create a composite index for filtering and sorting documents
CREATE INDEX CONCURRENTLY ix_documents_project_id_created_at_desc
ON documents (project_id, created_at DESC);
```

This index is tailored to the query, enabling PostgreSQL to locate the relevant project's documents and read them in the correct order directly from the index.

### Resultado Esperado

The new plan avoids the expensive `Sort` operation, resulting in a dramatic performance improvement.

```
                                                     QUERY PLAN
--------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.43..6.50 rows=20 width=52) (actual time=0.035..0.045 rows=20 loops=1)
   ->  Index Scan using ix_documents_project_id_created_at_desc on documents  (cost=0.43..320.00 rows=2000 width=52) (actual time=0.033..0.042 rows=20 loops=1)
         Index Cond: (project_id = 'some-project-uuid')
```

**Reducción de tiempo estimada**: From **~350ms** down to **~8ms**.

## 3. Endpoint: `GET /alerts`

This endpoint is used to query for alerts, often filtering by multiple criteria like `project_id`, `status`, and `severity`. This is a high-frequency query for monitoring and dashboards.

### Query Problemática

```sql
-- SQL for fetching alerts with multiple filters
SELECT alerts.id, alerts.message, alerts.project_id, alerts.status, alerts.severity, alerts.created_at
FROM alerts
WHERE alerts.project_id = :project_id_1
  AND alerts.status = :status_1
  AND alerts.severity = :severity_1
ORDER BY alerts.created_at DESC
LIMIT :param_1;
```

### Diagnóstico

A query with multiple `AND` conditions without a corresponding multi-column index is highly inefficient. PostgreSQL would likely use a `Seq Scan` or at best a single-column index and then filter the rest in memory.

```
                                                     QUERY PLAN
--------------------------------------------------------------------------------------------------------------------
 Limit  (cost=1500.60..1500.65 rows=20 width=60) (actual time=40.123..40.124 rows=20 loops=1)
   ->  Sort  (cost=1500.60..1500.65 rows=500 width=60) (actual time=40.121..40.122 rows=20 loops=1)
         Sort Key: created_at DESC
         ->  Seq Scan on alerts  (cost=0.00..1200.00 rows=500 width=60) (actual time=0.015..20.165 rows=500 loops=1)
               Filter: ((project_id = 'some-project-uuid') AND (status = 'open') AND (severity = 'critical'))
```

**Coste alto debido a `Seq Scan` con múltiples filtros**: The database scans the entire `alerts` table and applies each filter. This is extremely inefficient as the number of alerts grows.

### Solución

A composite index on `(project_id, status, severity)` is the perfect solution. The order of columns in the index is important and should match the most common query pattern. Since we also sort by `created_at`, we can add it to the index as well.

```sql
-- Create a composite index for filtering alerts
CREATE INDEX CONCURRENTLY ix_alerts_project_id_status_severity_created_at
ON alerts (project_id, status, severity, created_at DESC);
```

This index allows the database to efficiently locate alerts that match all three filter criteria and retrieve them in the desired sorted order.

### Resultado Esperado

The query plan will now use a fast `Index Scan`, avoiding the `Seq Scan` and `Sort`.

```
                                                     QUERY PLAN
--------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.43..7.50 rows=20 width=60) (actual time=0.055..0.065 rows=20 loops=1)
   ->  Index Scan using ix_alerts_project_id_status_severity_created_at on alerts  (cost=0.43..400.00 rows=500 width=60) (actual time=0.053..0.062 rows=20 loops=1)
         Index Cond: ((project_id = 'some-project-uuid') AND (status = 'open') AND (severity = 'critical'))
```

**Reducción de tiempo estimada**: From **~500ms** down to **~10ms**.

## 4. Optimización ORM: El Problema N+1

Beyond indexing, how the application retrieves data from related tables is critical. The N+1 query problem is a common performance bottleneck caused by lazy loading in ORMs.

### El Problema

Consider a scenario where we fetch 10 projects and for each project, we want to display the 5 most recent documents.

**Código ineficiente (N+1):**
```python
# 1. Fetch N projects (1 query)
projects = session.query(Project).where(Project.tenant_id == tenant_id).limit(10).all()

# 2. For each project, fetch its documents (N queries)
for project in projects:
    # This triggers a new query for every project!
    documents = project.documents  # <-- LAZY LOAD = 1 query per project
    print(f"Project: {project.name}, Documents: {[doc.name for doc in documents]}")
```
En total, esto resulta en **1 (para los proyectos) + 10 (uno por cada proyecto) = 11 queries**. Esto no escala. Si pedimos 100 proyectos, haremos 101 queries.

### Solución: Carga Ansiosa (Eager Loading)

SQLAlchemy provides strategies to solve this by pre-loading the related data in a single, more efficient query.

#### `joinedload`

Usa un `LEFT OUTER JOIN` para traer los proyectos y sus documentos en una sola consulta. Es ideal para relaciones "one-to-many" donde la cantidad de "many" no es masiva.

```python
from sqlalchemy.orm import joinedload

# Fetches projects and their documents in a single JOIN query
projects = (
    session.query(Project)
    .options(joinedload(Project.documents))
    .where(Project.tenant_id == tenant_id)
    .limit(10)
    .all()
)

# No more queries are issued inside the loop
for project in projects:
    documents = project.documents  # Data is already loaded
```
**Total Queries: 1**

#### `selectinload`

Usa una segunda consulta con un `WHERE ... IN (...)` para cargar los datos relacionados. Es más eficiente que `joinedload` cuando la tabla relacionada es grande o cuando se cargan múltiples relaciones "to-many", ya que evita el producto cartesiano de un `JOIN` masivo.

```python
from sqlalchemy.orm import selectinload

# 1. Fetch N projects (1 query)
projects = (
    session.query(Project)
    .options(selectinload(Project.documents))
    .where(Project.tenant_id == tenant_id)
    .limit(10)
    .all()
)
# SQLAlchemy issues a second query behind the scenes:
# SELECT ... FROM documents WHERE documents.project_id IN (id_1, id_2, ..., id_10)

# No more queries are issued inside the loop
for project in projects:
    documents = project.documents # Data is already loaded
```
**Total Queries: 2** (pero mucho más eficiente que N+1)

### Recomendación

- **Usar `joinedload`** para relaciones simples "one-to-one" o "many-to-one".
- **Preferir `selectinload`** para relaciones "one-to-many" para evitar `JOIN`s masivos y mejorar la eficiencia.

En todos los endpoints que devuelven listas (como `GET /projects`), se debe auditar el código y aplicar `selectinload` o `joinedload` para las relaciones que se acceden con frecuencia.

---

Last Updated: 2026-02-13

Changelog:
- 2026-02-13: Added metadata block during repository-wide docs format pass.
